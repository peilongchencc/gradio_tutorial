"""
éŸ³é¢‘å¤ªé•¿ä¼šè¢«æˆªæ–­ã€‚
"""
from transformers import WhisperForConditionalGeneration, WhisperProcessor
import torch
import gradio as gr
from gradio.data_classes import FileData
import numpy as np

class AudioTranscriber:
    def __init__(self, model_path):
        """
        åˆå§‹åŒ–éŸ³é¢‘è½¬å½•å™¨ã€‚
        
        å‚æ•°:
            model_path: æ¨¡å‹å’Œå¤„ç†å™¨çš„æœ¬åœ°è·¯å¾„ã€‚
        """
        print("å¼€å§‹åŠ è½½è¯­éŸ³æ¨¡å‹")
        self.model = WhisperForConditionalGeneration.from_pretrained(model_path)
        self.processor = WhisperProcessor.from_pretrained(model_path, language="chinese", task="transcribe")

        # ç¡®ä¿ä½¿ç”¨CUDAï¼Œå¦‚æœå¯ç”¨
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model.to(self.device)
        
        print("è¯­éŸ³æ¨¡å‹åŠ è½½æˆåŠŸğŸ…ğŸ…ğŸ…")

    def transcribe(self, audio_file_path):
        """
        è½¬å½•æŒ‡å®šéŸ³é¢‘æ–‡ä»¶çš„å†…å®¹ã€‚
        
        å‚æ•°:
            audio_file_path: éŸ³é¢‘æ–‡ä»¶çš„è·¯å¾„ã€‚
            
        è¿”å›:
            éŸ³é¢‘å†…å®¹çš„æ–‡æœ¬è½¬å½•ã€‚
        """
        payload = FileData(path=audio_file_path)
        # print(payload.path) # record_1213_002.wav

        audio_handle = gr.Audio()
        # srå³sampling rate(é‡‡æ ·ç‡), yå³audio data as numpy arrayã€‚
        sr, y = audio_handle.preprocess(payload)
        # (16000, array([  0,   0,   0, ..., 198, 333, 373], dtype=int16))
        y = y.astype(np.float32)
        # å½’ä¸€åŒ–éŸ³é¢‘æ•°æ®ï¼Œä½¿å…¶æŒ¯å¹…ä½äº[-1, 1]
        max_abs_y = np.max(np.abs(y))
        # é¿å…é™¤ä»¥0çš„é—®é¢˜
        if max_abs_y > 0:  # å¦‚æœæœ€å¤§ç»å¯¹å€¼å¤§äº0ï¼Œé¿å…æ‰§è¡Œé™¤ä»¥0çš„æ“ä½œ
            y /= max_abs_y
        # é¢„å¤„ç†éŸ³é¢‘
        inputs = self.processor(y, sampling_rate=sr, return_tensors="pt")
        input_values = inputs.input_features.to(self.device)

        # æ‰§è¡Œæ¨æ–­
        with torch.no_grad():
            generated_ids = self.model.generate(input_values)

        # ä½¿ç”¨generated_idsè€Œä¸æ˜¯ç›´æ¥ä»logitsè·å–predicted_ids
        transcription = self.processor.decode(
            generated_ids[0], 
            skip_special_tokens=True    # ä½¿ç”¨`skip_special_tokens=True`ä¿è¯è¾“å‡ºå¹²å‡€ã€‚
            )

        return transcription

# ä½¿ç”¨ç¤ºä¾‹
model_path = "large-v3"  # æ¨¡å‹çš„æœ¬åœ°è·¯å¾„
# è¿™é‡Œä½¿ç”¨çš„æ˜¯HFå¼€æºçš„"openai/whisper-large-v3"
# ç¬”è€…ä½¿ç”¨çš„ NVIDIA A100-PCIE-40GB "openai/whisper-large-v3" è¿è¡Œæ—¶å ç”¨çš„æ˜¾å­˜ä½ 7269MiB / 40960MiBã€‚
transcriber = AudioTranscriber(model_path)

# éŸ³é¢‘æ–‡ä»¶è·¯å¾„
audio_file_path = "record_1213_002.wav"
print("è¯†åˆ«ç»“æœ:", transcriber.transcribe(audio_file_path))